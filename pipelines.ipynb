{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 8 step process to display a goal value\n",
    "1. Get prompt as string\n",
    "2. Chain1: LCEL that guarantees a schema that fits step 3, or fails\n",
    "3. Perform Tavily query\n",
    "4. Chain2: LCEL that extracts most relevant url\n",
    "5. Load documents into a docs object\n",
    "6. Embed docs as a vectorstore and create a retriever\n",
    "7. Chain3: LCEL that guarantees a schema that fits step 8\n",
    "8. Display the goal value\n",
    "\n",
    "For this task, the prompt is a specific question about a given college. The goal value results from the highest quality source publically available, the common data set officially released by the university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a 8 step process to display a goal value\n",
    "1. Get prompt as string\n",
    "2. Chain1: LCEL that guarantees a schema that fits step 3, or fails\n",
    "3. Perform Tavily query\n",
    "4. Chain2: LCEL that extracts most relevant url\n",
    "5. Load documents into a docs object\n",
    "6. Embed docs as a vectorstore and create a retriever\n",
    "7. Chain3: LCEL that guarantees a schema that fits step 8\n",
    "8. Display the goal value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from langchain_community.utils.openai_functions import (\n",
    "    convert_pydantic_to_openai_function,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from langchain.tools import DuckDuckGoSearchRun\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from models import get_together_fn_mix\n",
    "ACTIVE_LLM = get_together_fn_mix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "# Get prompt as string\n",
    "USER_QUERY = \"What are admissions rates for Santa Clara University?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are a helpful assistant\"), (\"user\", \"{input}\")]\n",
    ")\n",
    "PARSER = JsonOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:\n",
    "# Chain1: LCEL that guarantees a schema that fits step 3, or fails\n",
    "class SearchCollege(BaseModel):\n",
    "    \"\"\"Construct a web search for a college\"\"\"\n",
    "    query: str = Field(description=\"Optimized query for search engine, including college name\")\n",
    "    college: str = Field(description=\"Name of the college. Empty string if not specified\")\n",
    "def is_chain1_valid(response_object):\n",
    "    return response_object[0]['arguments']['college'] != ''\n",
    "\n",
    "college_functions = [convert_pydantic_to_openai_function(SearchCollege)]\n",
    "chain1 = PROMPT | ACTIVE_LLM.bind(functions=college_functions, function_call={\"name\": \"SearchCollege\"})\n",
    "print(\"Successfully constructed chain1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call chain1\n",
    "chain1_prompt = USER_QUERY\n",
    "response = chain1.invoke({\"input\": chain1_prompt})\n",
    "response_object = PARSER.parse(response.content)\n",
    "if not is_chain1_valid(response_object):\n",
    "    raise ValueError(\"Chain1 failed\")\n",
    "# print(response_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:\n",
    "# Perform Tavily query\n",
    "search = TavilySearchResults(max_results=5)\n",
    "def get_tavily_query(response_object):\n",
    "    assert is_chain1_valid(response_object), \"Chain1 output is not valid\"\n",
    "    college = response_object[0]['arguments']['college']\n",
    "    query = college + \" Common Data Set 2023 filetype:pdf\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize Tavily query\n",
    "print(response_object)\n",
    "final_query = get_tavily_query(response_object)\n",
    "print(final_query)\n",
    "COLLEGE_NAME = response_object[0]['arguments']['college']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Tavily search\n",
    "results = search.invoke(final_query)\n",
    "print(\"Top 5 results from Tavily:\")\n",
    "for res in results:\n",
    "    print(res[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4:\n",
    "# Extract relevant url(s)\n",
    "def format_url_choice_string(urls, college):\n",
    "    return f\"Choose the most relevant url index for {college}: \\n\" + \"\\n\".join([f\"{i}: {url}\" for i, url in enumerate(urls)])\n",
    "chain2_needed = False\n",
    "chain2 = None\n",
    "if not results:\n",
    "    raise ValueError(\"No results found\")\n",
    "urls = [result['url'] for result in results]\n",
    "assert len(urls) > 0, \"No urls found\"\n",
    "if len(urls) == 1:\n",
    "    print('Skipping chain2')\n",
    "else:\n",
    "    print('Selecting the best url using chain2')\n",
    "    chain2_needed = True\n",
    "\n",
    "if chain2_needed:\n",
    "    class selectUrl(BaseModel):\n",
    "        \"\"\"Choose the most relevant url index for the given college.\"\"\"\n",
    "        index: int = Field(description=\"The index of the url to select\")\n",
    "    select_url_functions = [convert_pydantic_to_openai_function(selectUrl)]\n",
    "    chain2 = PROMPT | ACTIVE_LLM.bind(functions=select_url_functions, function_call={\"name\": \"selectUrl\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call chain2 if needed to select the most relevant url\n",
    "relevant_url = None\n",
    "if chain2 is not None:\n",
    "    chain2_prompt = format_url_choice_string(urls, COLLEGE_NAME)\n",
    "    response = chain2.invoke({\"input\": chain2_prompt})\n",
    "    response_object = PARSER.parse(response.content)\n",
    "    # print(response_object)\n",
    "    assert response_object[0]['arguments']['index'] < len(urls), \"Index out of range\"\n",
    "    relevant_url = urls[response_object[0]['arguments']['index']]\n",
    "else:\n",
    "    relevant_url = urls[0]\n",
    "print(relevant_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5:\n",
    "# Load documents into a docs object\n",
    "loader = PyPDFLoader(relevant_url)\n",
    "pages = loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
